{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sfpddistricts.geojson.json') as data_file:    \n",
    "    data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinates = []\n",
    "for index in xrange(10):\n",
    "    if index == 1: coordinates.append(data['features'][index]['geometry']['coordinates'][0][0])\n",
    "    else: coordinates.append(data['features'][index]['geometry']['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_lat = {}\n",
    "latitudes = []\n",
    "dist_lon = {}\n",
    "longitudes = []\n",
    "\n",
    "for i in range(10):\n",
    "    longitudes = []\n",
    "    for j in range(len(coordinates[i])):\n",
    "        longitudes.append(coordinates[i][j][0])\n",
    "    dist_lon[i] = longitudes    \n",
    "    \n",
    "for i2 in range(10):\n",
    "    latitudes = []\n",
    "    for j2 in range(len(coordinates[i2])):\n",
    "        latitudes.append(coordinates[i2][j2][1])\n",
    "    dist_lat[i2] = latitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max lat: 37.811575\n",
      "max lon: -122.356983\n"
     ]
    }
   ],
   "source": [
    "def find_max(dic):\n",
    "    \n",
    "    max_ini = None\n",
    "    for key, values in dic.iteritems():\n",
    "        max_val = max(values)\n",
    "        \n",
    "        if max_val > max_ini:\n",
    "            max_ini = max_val\n",
    "            \n",
    "    return max_ini\n",
    "\n",
    "max_lon = find_max(dist_lon)\n",
    "max_lat = find_max(dist_lat)\n",
    "\n",
    "print \"max lat: %f\" % max_lat\n",
    "print \"max lon: %f\" % max_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min lon: -122.514949\n"
     ]
    }
   ],
   "source": [
    "def find_min(dic):\n",
    "    \n",
    "    min_ini = 0\n",
    "    for key, values in dic.iteritems():\n",
    "        min_val = min(values)\n",
    "\n",
    "        if min_val < min_ini:\n",
    "            min_ini = min_val\n",
    "            \n",
    "    return min_ini\n",
    "\n",
    "min_lon = find_min(dist_lon)\n",
    "\n",
    "print \"min lon: %f\" % min_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def readfile(filename):\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "filename = 'SFPD_Incidents_-_from_1_January_2003.csv'\n",
    "#read file\n",
    "dataset = readfile(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract year from date column in the CSV file and only keep them from 2003 to 2015 (full years in the database)\n",
    "def filteryears(dataset):\n",
    "    \n",
    "    #Create a new column with the extracted years from the date column in the CSV file\n",
    "    dataset['Year'] = [int(date.split(\"/\")[-1]) for date in dataset['Date']]\n",
    "    #filter the dataset. Just keep the rows that do not belong to year 2016.\n",
    "    dataset = dataset[dataset['Year'] != 2016]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "db_15 = filteryears(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get PROSTITUTION subset\n",
    "\n",
    "db_PROST = db_15[db_15['Category'] == 'PROSTITUTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def geo_data(df):\n",
    "    \n",
    "    #get latitudes \n",
    "    latitudes = [float(item) for item in df['Y']]\n",
    "    #get longitudes \n",
    "    longitudes = [float(item) for item in df['X']]\n",
    "    #build X as a list of lists \n",
    "    X = [[latitudes[item], longitudes[item]] for item in range(len(latitudes))]\n",
    "    \n",
    "    return X\n",
    "\n",
    "X = geo_data(db_PROST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "districts = list(set(db_PROST['PdDistrict']))\n",
    "map_dict = {district:index for index, district in enumerate(districts)}\n",
    "\n",
    "def ylabel(df, map_dict):\n",
    "    \n",
    "    y = []    \n",
    "    for item in df['PdDistrict']:\n",
    "        y.append(map_dict[item])\n",
    "        \n",
    "    return y\n",
    "\n",
    "Y = ylabel(db_PROST, map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "K=3 \n",
    "\n",
    "def KNN(X,Y,X_test,K):\n",
    "\n",
    "    #we first create an instance of Neighbours Classifier\n",
    "    knn=neighbors.KNeighborsClassifier(n_neighbors=K)\n",
    "    #then we fit the data in order to train the classifier\n",
    "    knn.fit(X,Y)\n",
    "    #predict the labels of the coordinates in the grid\n",
    "    Z = knn.predict(X_test)\n",
    "    \n",
    "    return Z\n",
    "\n",
    "Z = KNN(X_train, Y_train, X_test, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('lat_lon.csv', 'w') as fp:\n",
    "    f = csv.writer(fp, delimiter=',')\n",
    "    f.writerows(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
